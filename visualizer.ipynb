{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visual run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "# np.set_printoptions(precision=3, suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from ifcn import unet\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from dataset import SegmentationDataset\n",
    "from metrics import dice_loss, dice_score, seg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='output.log', filemode='w',\n",
    "                    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ######################## Hyperparameters #################################\n",
    "    train_batch_size = 10  # orig 10, 5 for large original image size\n",
    "    validation_batch_size = 5  # orig 10\n",
    "    learning_rate = 0.001\n",
    "    num_classes = 26\n",
    "\n",
    "    # SET EPOCH (STAR)\n",
    "    num_epochs = 20\n",
    "\n",
    "    # Data Directory\n",
    "    input_data_dir = mask_json = r'data'\n",
    "\n",
    "    # Mask Json directory\n",
    "    mask_json = r'data/mapping.json'\n",
    "\n",
    "    # Image Transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    img_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Instantiate DataSets\n",
    "    train_dataset = SegmentationDataset(input_data_dir, 'train', mask_json, transforms=train_transform)\n",
    "    val_dataset   = SegmentationDataset(input_data_dir, 'val', mask_json, transforms=img_transform)\n",
    "    test_dataset  = SegmentationDataset(input_data_dir, 'test', mask_json, transforms=img_transform)\n",
    "\n",
    "    # Instantiate dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=validation_batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # gpu or cpu\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initializations\n",
    "    model = unet(num_classes=num_classes, useBN=True)\n",
    "    model = model.to(device)\n",
    "    weights_init(model)\n",
    "    loss_fn = dice_loss()\n",
    "\n",
    "    # other loss function options:\n",
    "    # loss_fn = GeneralizedDiceLoss()\n",
    "    # loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    ############################ INITIALIZE ############################\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    displayBatch =  False\n",
    "    displayEpoch =  True\n",
    "    epoch_train_loss = []\n",
    "    epoch_train_accuracy_per_class = []\n",
    "    epoch_train_accuracy_average = []\n",
    "\n",
    "    epoch_val_loss = []\n",
    "    epoch_val_accuracy_per_class = []\n",
    "    epoch_val_accuracy_average = []\n",
    "\n",
    "    for epic in range(num_epochs):\n",
    "        \n",
    "        # Put model in training mode\n",
    "        model.train()\n",
    "        correct = 0  # for class identification\n",
    "        \n",
    "        train_total = 0\n",
    "        train_batch_loss = 0\n",
    "        train_batch_accuracy = np.empty((0, num_classes))\n",
    "        \n",
    "        for i, sample in enumerate(train_dataloader):\n",
    "            img_patch = sample['img']  # x\n",
    "            ins_patch = sample['ins']  # x part 2\n",
    "            gt_patch = sample['gt']  # y, ground truth\n",
    "            weight = sample['weight']\n",
    "            c_label = sample['c_label']  # torch.Size([10]), tensor([1., 0., ...])\n",
    "\n",
    "            # concatenate IFCN train patch: image and instance memory\n",
    "            input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
    "            \n",
    "            # move inputs to device\n",
    "            if torch.cuda.is_available():\n",
    "                input_patch = input_patch.to(device)\n",
    "                gt_patch = gt_patch.to(device)\n",
    "                weight = weight.to(device)\n",
    "                c_label = c_label.to(device)\n",
    "            \n",
    "            # Loop over model\n",
    "            optimizer.zero_grad()\n",
    "            # output = model.forward(x)  # N K H W\n",
    "            S, C = model.forward(input_patch.float())  # C is size [10, 1], squeeze?\n",
    "\n",
    "            # calculate dice coefficient\n",
    "            train_dice_coeff = dice_score(S, gt_patch)\n",
    "\n",
    "            # calculate dice per-class loss - use IFCN train loss instead\n",
    "            # loss = loss_fn(S, gt_patch)\n",
    "            # loss.backward()\n",
    "\n",
    "            # calculate total loss (with weight and completeness classification)\n",
    "            loss_lambda = 0.1  # avoid using lambda as variable name\n",
    "            FP, FN = seg_loss(S, gt_patch, weight)\n",
    "            s_loss = loss_lambda * FP + FN\n",
    "            c_loss = F.binary_cross_entropy(torch.squeeze(C), c_label)\n",
    "            train_loss = s_loss + c_loss\n",
    "\n",
    "            logging.info(\"train_dice_coeff: %s, S Loss: %s, C Loss: %s\" % (train_dice_coeff, s_loss.item(), c_loss.item()))\n",
    "\n",
    "            # ignore this for now\n",
    "#             C_one_hot = torch.flatten(C.round())  # torch.Size([10, 1])\n",
    "#             print('C flatten shape is:',np.shape(C.round()))  # no change\n",
    "#             print('C flatten type is:',type(C.round()))\n",
    "#             print('C flatten is:',C.round())\n",
    "#             if C_one_hot == c_label:\n",
    "#                 correct = 1\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Dice score for training\n",
    "            train_batch_accuracy = np.vstack((train_batch_accuracy, train_dice_coeff))\n",
    "            \n",
    "            # make transition a little easier by just renaming variables for this section\n",
    "            output = S\n",
    "            y = gt_patch\n",
    "            x = input_patch\n",
    "            loss = train_loss\n",
    "            \n",
    "            # Display\n",
    "            if displayBatch is True:\n",
    "                _, y_hat = torch.max(output, dim=1) # argmax over classes\n",
    "                _, y_flat = torch.max(y.detach().clone(), dim=1)\n",
    "                disp_mask = y_flat.cpu().numpy()\n",
    "                disp_y_hat = y_hat.cpu().numpy()\n",
    "                plt.figure(figsize=(12,8))\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.imshow(disp_mask[0])\n",
    "                plt.title(\"Target\")\n",
    "                plt.subplot(1,2,2)\n",
    "                plt.imshow(disp_y_hat[0])\n",
    "                plt.title(\"Predicted\")\n",
    "                plt.show()\n",
    "            \n",
    "            # Since loss is averaged over class and batch, to get total loss we need to multiply by NK\n",
    "            N, K, H, W = x.shape\n",
    "            train_total += N*K\n",
    "            train_batch_loss += loss.item() * N * K\n",
    "\n",
    "        if displayEpoch is True:\n",
    "            _, y_hat = torch.max(output, dim=1) # argmax over classes\n",
    "            _, y_flat = torch.max(y.detach().clone(), dim=1)\n",
    "            disp_mask = y_flat.cpu().numpy()\n",
    "            disp_y_hat = y_hat.cpu().numpy()\n",
    "            plt.figure(figsize=(12,8))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(disp_mask[0])\n",
    "            plt.title(\"Target\")\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(disp_y_hat[0])\n",
    "            plt.title(\"Predicted\")\n",
    "            plt.show()\n",
    "            \n",
    "        # Append to epoch loss/accuracy\n",
    "        epoch_train_loss.append(train_batch_loss / train_total)\n",
    "        a = train_batch_accuracy.mean(axis=0)\n",
    "        epoch_train_accuracy_per_class.append(a) # mean over class to get per class accuracy\n",
    "        epoch_train_accuracy_average.append(train_batch_accuracy.mean())\n",
    "        \n",
    "        print('='*50 + \" Training \" + '='*50)\n",
    "        print(f'Epoch: {epic}, Train Loss: {epoch_train_loss[-1]}, Average Dice Score: {epoch_train_accuracy_average[-1]}')\n",
    "        print('Dice Score Per Class')\n",
    "        print('0: {0:.2f} 1: {1:.2f} 2: {2:.2f} 3: {3:.2f} 4: {4:.2f} 5: {5:.2f} 6: {6:.2f} 7: {7:.2f} 8: {8:.2f} 9: {9:.2f} 10: {10:.2f} 11: {11:.2f} 12: {12:.2f} 13: {13:.2f} 14: {14:.2f} 15: {15:.2f} 16: {16:.2f} 17: {17:.2f} 18: {18:.2f} 19: {19:.2f} 20: {20:.2f} 21: {21:.2f} 22: {22:.2f} 23: {23:.2f} 24: {24:.2f} 25: {25:.2f}'.format(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7], a[8], a[9], a[10], a[11], a[12], a[13], a[14], a[15], a[16], a[17], a[18], a[19], a[20], a[21], a[22], a[23], a[24], a[25]))\n",
    "        \n",
    "        # Put model in validation mode\n",
    "        model.eval()\n",
    "\n",
    "        val_total = 0\n",
    "        val_batch_loss = 0\n",
    "        val_batch_accuracy = np.empty((0, num_classes))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for i, sample in enumerate(val_dataloader):\n",
    "                img_patch = sample['img']  # x\n",
    "                ins_patch = sample['ins']  # x part 2\n",
    "                gt_patch = sample['gt']  # y, ground truth\n",
    "                weight = sample['weight']\n",
    "                c_label = sample['c_label']\n",
    "                \n",
    "                # concatenate IFCN train patch: image and instance memory\n",
    "                input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
    "\n",
    "                # move inputs to device\n",
    "                if torch.cuda.is_available():\n",
    "                    input_patch = input_patch.to(device)\n",
    "                    gt_patch = gt_patch.to(device)\n",
    "                    weight = weight.to(device)\n",
    "                    c_label = c_label.to(device)\n",
    "                \n",
    "                S, C = model.forward(input_patch.float())\n",
    "                \n",
    "                # calculate total loss (with weight and completeness classification)\n",
    "                loss_lambda = 0.1  # avoid using lambda as variable name\n",
    "                FP, FN = seg_loss(S, gt_patch, weight)\n",
    "                s_loss = loss_lambda * FP + FN\n",
    "                c_loss = F.binary_cross_entropy(torch.squeeze(C), c_label)\n",
    "                train_loss = s_loss + c_loss\n",
    "                \n",
    "                # calculate dice coefficient\n",
    "                train_dice_coeff = dice_score(S, gt_patch)\n",
    "                \n",
    "                # Dice score for training\n",
    "                val_batch_accuracy = np.vstack((val_batch_accuracy, train_dice_coeff))\n",
    "                \n",
    "                # make transition easier, as before\n",
    "                output = S\n",
    "                y = gt_patch\n",
    "                x = input_patch\n",
    "                loss = train_loss\n",
    "                \n",
    "                # Since loss is averaged over class and batch, to get total loss we need to multiply by NK\n",
    "                N, K, H, W = x.shape\n",
    "                val_total += N*K\n",
    "                val_batch_loss += train_loss.item() * N * K\n",
    "                \n",
    "            # Append to epoch loss/accuracy\n",
    "            epoch_val_loss.append(val_batch_loss / val_total)\n",
    "            b = val_batch_accuracy.mean(axis=0)\n",
    "            epoch_val_accuracy_per_class.append(a) # mean over class to get per class accuracy\n",
    "            epoch_val_accuracy_average.append(val_batch_accuracy.mean())\n",
    "            \n",
    "            print('='*49 + \" Validation \" + '='*49)\n",
    "            print(f'Epoch: {epic}, Val Loss: {epoch_val_loss[-1]}, Average Dice Score: {epoch_val_accuracy_average[-1]}')\n",
    "            print('Dice Score Per Class')\n",
    "            print('0: {0:.2f} 1: {1:.2f} 2: {2:.2f} 3: {3:.2f} 4: {4:.2f} 5: {5:.2f} 6: {6:.2f} 7: {7:.2f} 8: {8:.2f} 9: {9:.2f} 10: {10:.2f} 11: {11:.2f} 12: {12:.2f} 13: {13:.2f} 14: {14:.2f} 15: {15:.2f} 16: {16:.2f} 17: {17:.2f} 18: {18:.2f} 19: {19:.2f} 20: {20:.2f} 21: {21:.2f} 22: {22:.2f} 23: {23:.2f} 24: {24:.2f} 25: {25:.2f}'.format(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7], a[8], a[9], a[10], a[11], a[12], a[13], a[14], a[15], a[16], a[17], a[18], a[19], a[20], a[21], a[22], a[23], a[24], a[25]))\n",
    "            print('='*110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla K80\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:arcade]",
   "language": "python",
   "name": "conda-env-arcade-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
