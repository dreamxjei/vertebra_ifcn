{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visual run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "# np.set_printoptions(precision=3, suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from ifcn import unet\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from dataset import SegmentationDataset\n",
    "from metrics import dice_loss, dice_score, seg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='output.log', filemode='w',\n",
    "                    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ######################## Hyperparameters #################################\n",
    "    train_batch_size = 10  # orig 10, 5 for large original image size\n",
    "    validation_batch_size = 5  # orig 10\n",
    "    learning_rate = 0.001\n",
    "    num_classes = 26\n",
    "\n",
    "    # SET EPOCH (STAR)\n",
    "    num_epochs = 20\n",
    "\n",
    "    # Data Directory\n",
    "    input_data_dir = mask_json = r'data'\n",
    "\n",
    "    # Mask Json directory\n",
    "    mask_json = r'data/mapping.json'\n",
    "\n",
    "    # Image Transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    img_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Instantiate DataSets\n",
    "    train_dataset = SegmentationDataset(input_data_dir, 'train', mask_json, transforms=train_transform)\n",
    "    val_dataset   = SegmentationDataset(input_data_dir, 'val', mask_json, transforms=img_transform)\n",
    "    test_dataset  = SegmentationDataset(input_data_dir, 'test', mask_json, transforms=img_transform)\n",
    "\n",
    "    # Instantiate dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=validation_batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # gpu or cpu\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initializations\n",
    "    model = unet(num_classes=num_classes, useBN=True)\n",
    "    model = model.to(device)\n",
    "    weights_init(model)\n",
    "    loss_fn = dice_loss()\n",
    "\n",
    "    # other loss function options:\n",
    "    # loss_fn = GeneralizedDiceLoss()\n",
    "    # loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    ############################ INITIALIZE ############################\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    displayBatch =  False\n",
    "    displayEpoch =  True\n",
    "    epoch_train_loss = []\n",
    "    epoch_train_accuracy_per_class = []\n",
    "    epoch_train_accuracy_average = []\n",
    "\n",
    "    epoch_val_loss = []\n",
    "    epoch_val_accuracy_per_class = []\n",
    "    epoch_val_accuracy_average = []\n",
    "\n",
    "    for epic in range(num_epochs):\n",
    "        print('starting epoch:', epic)\n",
    "        \n",
    "        # Put model in training mode\n",
    "        model.train()\n",
    "        correct = 0  # for class identification\n",
    "        \n",
    "        train_total = 0\n",
    "        train_batch_loss = 0\n",
    "        train_batch_accuracy = np.empty((0, num_classes))\n",
    "        \n",
    "        for i, sample in enumerate(train_dataloader):\n",
    "            img_patch = sample['img']  # x\n",
    "            ins_patch = sample['ins']  # x part 2\n",
    "            gt_patch = sample['gt']  # y, ground truth\n",
    "            weight = sample['weight']\n",
    "            c_label = sample['c_label']  # torch.Size([10]), tensor([1., 0., ...])\n",
    "\n",
    "            # concatenate IFCN train patch: image and instance memory\n",
    "            input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
    "            \n",
    "            # move inputs to device\n",
    "            if torch.cuda.is_available():\n",
    "                input_patch = input_patch.to(device)\n",
    "                gt_patch = gt_patch.to(device)\n",
    "                weight = weight.to(device)\n",
    "                c_label = c_label.to(device)\n",
    "            \n",
    "            # Loop over model\n",
    "            optimizer.zero_grad()\n",
    "            # output = model.forward(x)  # N K H W\n",
    "            S, C = model.forward(input_patch.float())  # C is size [10, 1], squeeze?\n",
    "\n",
    "            # calculate dice coefficient\n",
    "            train_dice_coeff = dice_score(S, gt_patch)\n",
    "\n",
    "            # calculate dice per-class loss - use IFCN train loss instead\n",
    "            # loss = loss_fn(S, gt_patch)\n",
    "            # loss.backward()\n",
    "\n",
    "            # calculate total loss (with weight and completeness classification)\n",
    "            loss_lambda = 0.1  # avoid using lambda as variable name\n",
    "            FP, FN = seg_loss(S, gt_patch, weight)\n",
    "            s_loss = loss_lambda * FP + FN\n",
    "            c_loss = F.binary_cross_entropy(torch.squeeze(C), c_label)\n",
    "            train_loss = s_loss + c_loss\n",
    "\n",
    "            logging.info(\"train_dice_coeff: %s, S Loss: %s, C Loss: %s\" % (train_dice_coeff, s_loss.item(), c_loss.item()))\n",
    "\n",
    "            # ignore this for now\n",
    "#             C_one_hot = torch.flatten(C.round())  # torch.Size([10, 1])\n",
    "#             print('C flatten shape is:',np.shape(C.round()))  # no change\n",
    "#             print('C flatten type is:',type(C.round()))\n",
    "#             print('C flatten is:',C.round())\n",
    "#             if C_one_hot == c_label:\n",
    "#                 correct = 1\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Dice score for training\n",
    "            train_batch_accuracy = np.vstack((train_batch_accuracy, train_dice_coeff))\n",
    "            \n",
    "            # make transition a little easier by just renaming variables for this section\n",
    "            output = S\n",
    "            y = gt_patch\n",
    "            x = input_patch\n",
    "            loss = train_loss\n",
    "            \n",
    "            # Display\n",
    "            if displayBatch is True:\n",
    "                _, y_hat = torch.max(output, dim=1) # argmax over classes\n",
    "                _, y_flat = torch.max(y.detach().clone(), dim=1)\n",
    "                disp_mask = y_flat.cpu().numpy()\n",
    "                disp_y_hat = y_hat.cpu().numpy()\n",
    "                plt.figure(figsize=(12,8))\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.imshow(disp_mask[0])\n",
    "                plt.title(\"Target\")\n",
    "                plt.subplot(1,2,2)\n",
    "                plt.imshow(disp_y_hat[0])\n",
    "                plt.title(\"Predicted\")\n",
    "                plt.show()\n",
    "            \n",
    "            # Since loss is averaged over class and batch, to get total loss we need to multiply by NK\n",
    "            N, K, H, W = x.shape\n",
    "            train_total += N*K\n",
    "            train_batch_loss += loss.item() * N * K\n",
    "\n",
    "        if displayEpoch is True:\n",
    "            _, y_hat = torch.max(output, dim=1) # argmax over classes\n",
    "            _, y_flat = torch.max(y.detach().clone(), dim=1)\n",
    "            disp_mask = y_flat.cpu().numpy()\n",
    "            disp_y_hat = y_hat.cpu().numpy()\n",
    "            plt.figure(figsize=(12,8))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(disp_mask[0])\n",
    "            plt.title(\"Target\")\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(disp_y_hat[0])\n",
    "            plt.title(\"Predicted\")\n",
    "            plt.show()\n",
    "            \n",
    "        # Append to epoch loss/accuracy\n",
    "        epoch_train_loss.append(train_batch_loss / train_total)\n",
    "        a = train_batch_accuracy.mean(axis=0)\n",
    "        epoch_train_accuracy_per_class.append(a) # mean over class to get per class accuracy\n",
    "        epoch_train_accuracy_average.append(train_batch_accuracy.mean())\n",
    "        \n",
    "        print('='*50 + \" Training \" + '='*50)\n",
    "        print(f'Epoch: {epic}, Train Loss: {epoch_train_loss[-1]}, Average Dice Score: {epoch_train_accuracy_average[-1]}')\n",
    "        print('Dice Score Per Class')\n",
    "        print('0: {0:.2f} 1: {1:.2f} 2: {2:.2f} 3: {3:.2f} 4: {4:.2f} 5: {5:.2f} 6: {6:.2f} 7: {7:.2f} 8: {8:.2f} 9: {9:.2f} 10: {10:.2f} 11: {11:.2f} 12: {12:.2f} 13: {13:.2f} 14: {14:.2f} 15: {15:.2f} 16: {16:.2f} 17: {17:.2f} 18: {18:.2f} 19: {19:.2f} 20: {20:.2f} 21: {21:.2f} 22: {22:.2f} 23: {23:.2f} 24: {24:.2f} 25: {25:.2f}'.format(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7], a[8], a[9], a[10], a[11], a[12], a[13], a[14], a[15], a[16], a[17], a[18], a[19], a[20], a[21], a[22], a[23], a[24], a[25]))\n",
    "        \n",
    "        # Put model in validation mode\n",
    "        model.eval()\n",
    "\n",
    "        val_total = 0\n",
    "        val_batch_loss = 0\n",
    "        val_batch_accuracy = np.empty((0, num_classes))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for i, sample in enumerate(val_dataloader):\n",
    "                img_patch = sample['img']  # x\n",
    "                ins_patch = sample['ins']  # x part 2\n",
    "                gt_patch = sample['gt']  # y, ground truth\n",
    "                weight = sample['weight']\n",
    "                c_label = sample['c_label']\n",
    "                \n",
    "                # concatenate IFCN train patch: image and instance memory\n",
    "                input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
    "\n",
    "                # move inputs to device\n",
    "                if torch.cuda.is_available():\n",
    "                    input_patch = input_patch.to(device)\n",
    "                    gt_patch = gt_patch.to(device)\n",
    "                    weight = weight.to(device)\n",
    "                    c_label = c_label.to(device)\n",
    "                \n",
    "                S, C = model.forward(input_patch.float())\n",
    "                \n",
    "                # calculate total loss (with weight and completeness classification)\n",
    "                loss_lambda = 0.1  # avoid using lambda as variable name\n",
    "                FP, FN = seg_loss(S, gt_patch, weight)\n",
    "                s_loss = loss_lambda * FP + FN\n",
    "                c_loss = F.binary_cross_entropy(torch.squeeze(C), c_label)\n",
    "                train_loss = s_loss + c_loss\n",
    "                \n",
    "                # calculate dice coefficient\n",
    "                train_dice_coeff = dice_score(S, gt_patch)\n",
    "                \n",
    "                # Dice score for training\n",
    "                val_batch_accuracy = np.vstack((val_batch_accuracy, train_dice_coeff))\n",
    "                \n",
    "                # make transition easier, as before\n",
    "                output = S\n",
    "                y = gt_patch\n",
    "                x = input_patch\n",
    "                loss = train_loss\n",
    "                \n",
    "                # Since loss is averaged over class and batch, to get total loss we need to multiply by NK\n",
    "                N, K, H, W = x.shape\n",
    "                val_total += N*K\n",
    "                val_batch_loss += train_loss.item() * N * K\n",
    "                \n",
    "            # Append to epoch loss/accuracy\n",
    "            epoch_val_loss.append(val_batch_loss / val_total)\n",
    "            b = val_batch_accuracy.mean(axis=0)\n",
    "            epoch_val_accuracy_per_class.append(a) # mean over class to get per class accuracy\n",
    "            epoch_val_accuracy_average.append(val_batch_accuracy.mean())\n",
    "            \n",
    "            print('='*49 + \" Validation \" + '='*49)\n",
    "            print(f'Epoch: {epic}, Val Loss: {epoch_val_loss[-1]}, Average Dice Score: {epoch_val_accuracy_average[-1]}')\n",
    "            print('Dice Score Per Class')\n",
    "            print('0: {0:.2f} 1: {1:.2f} 2: {2:.2f} 3: {3:.2f} 4: {4:.2f} 5: {5:.2f} 6: {6:.2f} 7: {7:.2f} 8: {8:.2f} 9: {9:.2f} 10: {10:.2f} 11: {11:.2f} 12: {12:.2f} 13: {13:.2f} 14: {14:.2f} 15: {15:.2f} 16: {16:.2f} 17: {17:.2f} 18: {18:.2f} 19: {19:.2f} 20: {20:.2f} 21: {21:.2f} 22: {22:.2f} 23: {23:.2f} 24: {24:.2f} 25: {25:.2f}'.format(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7], a[8], a[9], a[10], a[11], a[12], a[13], a[14], a[15], a[16], a[17], a[18], a[19], a[20], a[21], a[22], a[23], a[24], a[25]))\n",
    "            print('='*110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla K80\n",
      "starting epoch: 0\n",
      "dataloader looking in idir: data/train/385\n",
      "chosen vert is: 17\n",
      "img.shape is: (801, 640, 3)\n",
      "dataloader looking in idir: data/train/134\n",
      "chosen vert is: 15\n",
      "img.shape is: (846, 640, 3)\n",
      "dataloader looking in idir: data/train/291\n",
      "chosen vert is: 18\n",
      "img.shape is: (952, 640, 3)\n",
      "dataloader looking in idir: data/train/374\n",
      "chosen vert is: 13\n",
      "img.shape is: (1098, 640, 3)\n",
      "dataloader looking in idir: data/train/129\n",
      "chosen vert is: 19\n",
      "img.shape is: (786, 640, 3)\n",
      "dataloader looking in idir: data/train/273\n",
      "chosen vert is: 12\n",
      "img.shape is: (724, 640, 3)\n",
      "dataloader looking in idir: data/train/173\n",
      "chosen vert is: 15\n",
      "img.shape is: (790, 640, 3)\n",
      "dataloader looking in idir: data/train/122\n",
      "chosen vert is: 17\n",
      "img.shape is: (847, 640, 3)\n",
      "dataloader looking in idir: data/train/326\n",
      "chosen vert is: 14\n",
      "img.shape is: (863, 640, 3)\n",
      "dataloader looking in idir: data/train/311\n",
      "chosen vert is: 8\n",
      "img.shape is: (795, 640, 3)\n",
      "dataloader looking in idir: data/train/155\n",
      "chosen vert is: 8\n",
      "img.shape is: (803, 640, 3)\n",
      "dataloader looking in idir: data/train/43\n",
      "chosen vert is: 19\n",
      "img.shape is: (879, 640, 3)\n",
      "dataloader looking in idir: data/train/376\n",
      "chosen vert is: 23\n",
      "img.shape is: (843, 640, 3)\n",
      "dataloader looking in idir: data/train/143\n",
      "chosen vert is: 21\n",
      "img.shape is: (825, 640, 3)\n",
      "dataloader looking in idir: data/train/346\n",
      "chosen vert is: 12\n",
      "img.shape is: (810, 640, 3)\n",
      "dataloader looking in idir: data/train/31\n",
      "chosen vert is: 20\n",
      "img.shape is: (919, 640, 3)\n",
      "dataloader looking in idir: data/train/399\n",
      "chosen vert is: 13\n",
      "img.shape is: (942, 640, 3)\n",
      "dataloader looking in idir: data/train/379\n",
      "chosen vert is: 13\n",
      "img.shape is: (897, 640, 3)\n",
      "dataloader looking in idir: data/train/381\n",
      "chosen vert is: 23\n",
      "img.shape is: (843, 640, 3)\n",
      "dataloader looking in idir: data/train/268\n",
      "chosen vert is: 8\n",
      "img.shape is: (841, 640, 3)\n",
      "dataloader looking in idir: data/train/227\n",
      "chosen vert is: 12\n",
      "img.shape is: (732, 640, 3)\n",
      "dataloader looking in idir: data/train/77\n",
      "chosen vert is: 13\n",
      "img.shape is: (840, 640, 3)\n",
      "dataloader looking in idir: data/train/74\n",
      "chosen vert is: 21\n",
      "img.shape is: (734, 640, 3)\n",
      "dataloader looking in idir: data/train/258\n",
      "chosen vert is: 9\n",
      "img.shape is: (805, 640, 3)\n",
      "dataloader looking in idir: data/train/212\n",
      "chosen vert is: 11\n",
      "img.shape is: (895, 640, 3)\n",
      "dataloader looking in idir: data/train/375\n",
      "chosen vert is: 20\n",
      "img.shape is: (994, 640, 3)\n",
      "dataloader looking in idir: data/train/407\n",
      "chosen vert is: 13\n",
      "img.shape is: (818, 640, 3)\n",
      "dataloader looking in idir: data/train/54\n",
      "chosen vert is: 22\n",
      "img.shape is: (898, 640, 3)\n",
      "dataloader looking in idir: data/train/312\n",
      "chosen vert is: 13\n",
      "img.shape is: (947, 640, 3)\n",
      "dataloader looking in idir: data/train/253\n",
      "chosen vert is: 21\n",
      "img.shape is: (931, 640, 3)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 128, 128] at entry 0 and [3, 128, 87] at entry 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-48195ad04bef>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtrain_batch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mimg_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mins_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ins'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# x part 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/arcade/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/arcade/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/arcade/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/arcade/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/arcade/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/arcade/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 128, 128] at entry 0 and [3, 128, 87] at entry 5"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:arcade]",
   "language": "python",
   "name": "conda-env-arcade-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
